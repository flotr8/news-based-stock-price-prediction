{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlRep = 'https://markets.businessinsider.com/news/aapl-stock?p='\n",
    "response = requests.get(urlRep)\n",
    "response.status_code, response.reason\n",
    "headlines = []\n",
    "dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6989ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeadlines(response):\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.findAll('div', attrs = {'class': 'latest-news__story'})\n",
    "\n",
    "    for article in articles:\n",
    "        headline = article.find('a').text\n",
    "        date = article.find('time')['datetime']\n",
    "        headlines.append(headline)\n",
    "        dates.append(date)\n",
    "\n",
    "        if len(headlines) % 100 == 0:\n",
    "            print(len(headlines))\n",
    "            print(date)\n",
    "    \n",
    "    if len(articles) == 0:\n",
    "        print(\"0 links added, please check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlBI = 'https://markets.businessinsider.com/news/aapl-stock?p='\n",
    "#urlBI = 'https://markets.businessinsider.com/news/tsla-stock?p='\n",
    "\n",
    "#define pages to crawl dependent from test range\n",
    "pages = 300\n",
    "for i in range(1,pages):\n",
    "    response = requests.get(urlBI + str(i))\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code, response.reason)\n",
    "    getHeadlines(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df = pd.DataFrame({'Headline': headlines, 'Date': dates})\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Convert string to datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define timezone objects for European Summertime and New York\n",
    "europe_summertime = pytz.timezone('Europe/Paris')\n",
    "new_york = pytz.timezone('America/New_York')\n",
    "\n",
    "# Convert datetime object from European Summertime to New York\n",
    "df['Date'] = df['Date'].apply(lambda x: europe_summertime.localize(x, is_dst=None).astimezone(new_york).replace(tzinfo=None))\n",
    "\n",
    "df.to_csv('data/headlines/TSLA/BusinessInsider' + timestr + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e2662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cd9cba96be51690fdf2e89f48d9c24126dbd81f80c0eb8bb1b203fd33f1f943"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
