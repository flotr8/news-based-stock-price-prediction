{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from helpFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the required data from the response\n",
    "def getData(response):\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    if soup != None:\n",
    "        #news = soup.findAll(attrs = {'class': 'text__text__1FZLe text__dark-grey__3Ml43 text__regular__2N1Xr text__large__nEccO body__full_width__ekUdw body__large_body__FV5_X article-body__element__2p5pI'}) \n",
    "        try:\n",
    "            headline = soup.find('h1').text\n",
    "            dates = soup.findAll(attrs = {'class': 'date-line__date__23Ge-'})\n",
    "            if len(dates) > 0:\n",
    "                date = dates[1].text\n",
    "                time = dates[2].text\n",
    "                return headline, date, time\n",
    "        except:\n",
    "            print(\"Soup Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Latest prepared Data via Helpfunction Call for the source\n",
    "#paths = getLatestData('links_markets')\n",
    "paths = getLatestData('links')\n",
    "df = pd.DataFrame(columns = ['Headline', 'Date', 'Time', 'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through all paths, and execetues function \"getData\" to add to the Dataset\n",
    "pathList = paths['Path'].to_list()\n",
    "\n",
    "print(len(pathList))\n",
    "\n",
    "for i in range(1, len(pathList)):\n",
    "    baseReut = \"https://www.reuters.com\" + pathList[i]\n",
    "    response = requests.get(baseReut)\n",
    "    row = getData(response)\n",
    "    if row != None:\n",
    "        new_row = {'Headline': row[0], 'Date': row[1], 'Time':row[2], 'URL':baseReut}\n",
    "        df = df.append(new_row, ignore_index = True)\n",
    "        if len(df)% 100 == 0:\n",
    "            print(len(df))\n",
    "            print(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#Define output for the news crawled\n",
    "#df.to_csv('data/headlines/marketsNews/ReutersMarketNews' + timestr + '.csv')\n",
    "df.to_csv('data/headlines/Reuters' + timestr + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cd9cba96be51690fdf2e89f48d9c24126dbd81f80c0eb8bb1b203fd33f1f943"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
